{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Training Traffic Recog.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/acmarkes/traffic-sign-recog.git\r\n",
        "%cd /content/traffic-sign-recog\r\n",
        "!pip install gdown\r\n",
        "\r\n",
        "import gdown\r\n",
        "imgs = 'https://drive.google.com/uc?id=17an3cKGO1I2WlBPSa6zcAucL-jISSHEn'\r\n",
        "labels = 'https://drive.google.com/uc?id=17gFHTQvU0utSNm3XMv2I8Ud4IzuqDLTl'\r\n",
        "\r\n",
        "gdown.download(imgs, 'procTrainImages.joblib', quiet=False)\r\n",
        "gdown.download(labels, 'train_labels.joblib', quiet=False)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "fmo1MG5KIDxd",
        "outputId": "5c5863e5-20de-41bf-e0bb-feb6ee94a73a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import joblib\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import utils\r\n",
        "\r\n",
        "from tensorflow.python.client import device_lib\r\n",
        "print(device_lib.list_local_devices())"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wO1QDNXGz0Sl",
        "outputId": "f9beb72a-ef68-47ea-e675-7d086465d73a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "procTrainImages = joblib.load('procTrainImages.joblib')\r\n",
        "print(procTrainImages.shape)\r\n",
        "utils.sample_images(procTrainImages, seed_num=42)\r\n",
        "trainLabels = joblib.load('train_labels.joblib')\r\n",
        "print(len(trainLabels))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        },
        "id": "yKdcMjeXKAO5",
        "outputId": "045e12c8-25d3-4d8b-c14c-99a70a32e7f6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "img_tweaks = {\r\n",
        "    'featurewise_center':True,\r\n",
        "    'featurewise_std_normalization':True,\r\n",
        "    'rotation_range':20,\r\n",
        "    'width_shift_range':0.2,\r\n",
        "    'height_shift_range':0.2,\r\n",
        "}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "Xy_train, Xy_val = utils.get_dataset_partitions_tf(procTrainImages, trainLabels, gen_kws=img_tweaks)\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "k61g1hvIz4gL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "class ResidualUnit(keras.layers.Layer):\r\n",
        "    def __init__(self, filters, strides=1, activation=\"relu\", **kwargs):\r\n",
        "        super().__init__(**kwargs)\r\n",
        "        self.activation = keras.activations.get(activation)\r\n",
        "        self.main_layers = [\r\n",
        "            keras.layers.Conv2D(filters, 3, strides=strides,\r\n",
        "                                padding=\"same\", use_bias=False),\r\n",
        "            keras.layers.BatchNormalization(),\r\n",
        "            self.activation,\r\n",
        "            keras.layers.Conv2D(filters, 3, strides=1,\r\n",
        "                                padding=\"same\", use_bias=False),\r\n",
        "            keras.layers.BatchNormalization()]\r\n",
        "        self.skip_layers = []\r\n",
        "        if strides > 1:\r\n",
        "            self.skip_layers = [\r\n",
        "                keras.layers.Conv2D(filters, 1, strides=strides,\r\n",
        "                                    padding=\"same\", use_bias=False),\r\n",
        "                keras.layers.BatchNormalization()]\r\n",
        "\r\n",
        "    def call(self, inputs):\r\n",
        "        Z = inputs\r\n",
        "        for layer in self.main_layers:\r\n",
        "            Z = layer(Z)\r\n",
        "        skip_Z = inputs\r\n",
        "        for layer in self.skip_layers:\r\n",
        "            skip_Z = layer(skip_Z)\r\n",
        "        return self.activation(Z + skip_Z)\r\n",
        "\r\n",
        "\r\n",
        "model = keras.models.Sequential()\r\n",
        "model.add(keras.layers.Conv2D(64, 7, strides=2, input_shape=[32, 32, 1],\r\n",
        "                              padding=\"same\", use_bias=False))\r\n",
        "model.add(keras.layers.BatchNormalization())\r\n",
        "model.add(keras.layers.Activation(\"relu\"))\r\n",
        "model.add(keras.layers.MaxPool2D(pool_size=3, strides=2, padding=\"same\"))\r\n",
        "prev_filters = 64\r\n",
        "\r\n",
        "for filters in [64] * 3 + [128] * 4 + [256] * 6 + [512] * 3:\r\n",
        "    strides = 1 if filters == prev_filters else 2\r\n",
        "    model.add(ResidualUnit(filters, strides=strides))\r\n",
        "    prev_filters = filters\r\n",
        "\r\n",
        "model.add(keras.layers.GlobalAvgPool2D())\r\n",
        "model.add(keras.layers.Flatten())\r\n",
        "model.add(keras.layers.Dense(43, activation=\"softmax\"))\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "bb2onemiq3nb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\r\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"nadam\", metrics=[\"accuracy\"])\r\n",
        "history = model.fit(Xy_train, batch_size=32 ,epochs=3, validation_data=Xy_val, callbacks=[callback])\r\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "RbB0iJRlz9vG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "QLz8ZOtMz9jT"
      }
    }
  ]
}